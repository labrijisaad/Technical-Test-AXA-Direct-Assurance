{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"https://is1-ssl.mzstatic.com/image/thumb/Purple122/v4/05/e7/67/05e76784-3364-b535-7e20-b3f4946a56b6/AppIcon-0-0-1x_U007emarketing-0-0-0-7-0-0-sRGB-0-0-0-GLES2_U002c0-512MB-85-220-0-0.png/434x0w.webp\" style=\"height:150px\"></center>\n",
    "\n",
    "<hr style=\"border-width:2px;border-color:red\">\n",
    "<center><h1>Test Technique Data Scientist</h1></center>\n",
    "<center><h2> Mesure de la dérive </h2></center>\n",
    "<hr style=\"border-width:2px;border-color:red\">\n",
    "\n",
    "# Contexte\n",
    "\n",
    "La **dérive** en apprentissage automatique (ou **\"drift\"** en anglais) fait référence à un **changement dans les données d'entrée ou de sortie d'un modèle** de machine learning **après son entraînement initial**. Cela peut se produire lorsque les données utilisées pour entraîner le modèle ne **reflètent plus la réalité**, ou lorsque **les conditions du problème changent de manière significative**.\n",
    "\n",
    "La dérive des données peut affecter la précision du modèle de manière significative et peut entraîner des erreurs coûteuses dans les prévisions ou les décisions basées sur le modèle. Par conséquent, **il est important de surveiller régulièrement les performances du modèle** et de le mettre à jour en fonction des nouveaux jeux de données ou des nouvelles conditions du problème.\n",
    "\n",
    "# Objectif\n",
    "\n",
    "Dans ce test, vous allez implémenter des métriques permettant de mesurer la dérive d'un modèle dans un usecase de **e-commerce** où nous essayons de prédire le **panier total** (variable **`TotalCart`** : chiffre d'affaire total d'un client sur la période donnée) des clients en fonction des variables suivantes:\n",
    "* **`Age`** : âge du client en années.\n",
    "* **`Seniority`** : ancienneté du client en années.\n",
    "* **`Orders`** : Nombre de commandes effectuées sur la période précédente.\n",
    "* **`Items`** : Nombre d'items commandés sur la période précédente.\n",
    "* **`AverageDiscount`** : Réduction moyenne accordée au client sur la période précédente en pourcentage.\n",
    "* **`TopCategory`** : Catégorie de produits favorite du client.\n",
    "* **`BrowsingTime`** : Temps total passé sur le site web sur la période précédente en secondes.\n",
    "* **`EmailsOpened`** : Nombre de mails marketing ouverts par le client sur la période précédente.\n",
    "* **`SupportInteractions`** : Nombre d'interactions que le client a eu avec le service client sur la période précédente.\n",
    "\n",
    "Le jeu de données est décomposé en 4 périodes correspondant aux 4 trimestres de l'année 2022. Vous trouverez les données correspondant à chaque période dans les fichiers **`period_0.csv`**, **`period_1.csv`**, ..., **`period_3.csv`**.\n",
    "\n",
    "Vous allez d'abord **entraîner et évaluer un modèle de machine learning** sur les données de la **période 0**. On supposera que ce modèle sera utilisé pour effectuer les prédictions de panier total sur toute l'année 2022.\n",
    "\n",
    "Ensuite, vous devrez **implémenter des métriques de dérive** qui vous seront données et **effectuer une analyse** de celle-ci.\n",
    "\n",
    "# Entraînement du modèle\n",
    "\n",
    "* **Entraînez et validez** deux ou trois modèles de votre choix sur les données de la période 0. \n",
    "\n",
    "**Conseils**\n",
    "\n",
    "* Vous serez évalué sur votre **rigueur** et non sur les performances du modèle.\n",
    "\n",
    "\n",
    "* Il n'est pas nécessaire de faire une analyse exploratoire des données.\n",
    "\n",
    "\n",
    "* Il n'est pas nécessaire de faire de recherche d'hyperparamètres optimaux non plus mais vous pouvez le faire si vous le souhaitez."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insérez votre code ici\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Entrainez votre modèle sur toute la période 0** puis **testez votre modèle** sur les données des **périodes 1, 2 et 3**. Comment évolue la performance du modèle?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insérez votre code ici\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mesure de la dérive de variables catégorielles.\n",
    "\n",
    "Pour deux distributions de probabilités discrètes $P$ et $Q$, la **divergence de Kullback–Leibler** de $P$ par rapport à $Q$ est définie par:\n",
    "\n",
    "$$D_\\text{KL}(P \\parallel Q) = \\sum_{x\\in\\mathcal{X}} P(x) \\log\\left(\\frac{P(x)}{Q(x)}\\right)$$\n",
    "\n",
    "\n",
    "On définit la **divergence de Jensen-Shannon** comme une version lisse et symétrique de la divergence de Kullback-Leiber donnée par la formule suivante:\n",
    "\n",
    "$${\\rm JSD}(P \\parallel Q)= \\frac{1}{2}D(P \\parallel M)+\\frac{1}{2}D(Q \\parallel M)$$\n",
    "\n",
    "où $M=\\frac{1}{2}(P+Q)$\n",
    "\n",
    "### Exemple de calcul de $D_\\text{KL}(P \\parallel Q)$ : \n",
    "\n",
    "Soient $P$ =`[0.2, 0.3, 0.5]` et $Q$ =`[0.2, 0.4, 0.4]` deux vecteurs définissant une loi de probabilité discrete. Alors : \n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\begin{split}\n",
    "D_\\text{KL}(P \\parallel Q) & = P(0) \\log\\left(\\frac{P(0)}{Q(0)}\\right)\n",
    "                             + P(1) \\log\\left(\\frac{P(1)}{Q(1)}\\right)\n",
    "                             + P(2) \\log\\left(\\frac{P(2)}{Q(2)}\\right)\\\\ \\\\\n",
    "                           & = 0.2 \\log\\left(\\frac{0.2}{0.2}\\right)\n",
    "                             + 0.3 \\log\\left(\\frac{0.3}{0.4}\\right)\n",
    "                             + 0.5 \\log\\left(\\frac{0.5}{0.4}\\right) \\\\ \\\\\n",
    "                           & = 0.02526...\n",
    "\\end{split}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "### Exercice\n",
    "\n",
    "* Implémenter des fonctions nommées **`KLDivergence(P, Q)`** et **`JSDivergence(P, Q)`** permettant de calculer les métriques définies ci-dessus.\n",
    "\n",
    "**Conseils**:\n",
    "* Utiliser la librairie Numpy permettant de facilement effectuer des calculs d'algèbre linéaire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "\n",
    "P = np.array([0.2, 0.3, 0.5])\n",
    "Q = np.array([0.2, 0.4, 0.4])\n",
    "\n",
    "def KLDivergence(P, Q):\n",
    "    \n",
    "    # Insérez votre code ici\n",
    "    \n",
    "    return None \n",
    "\n",
    "def JSDivergence(P, Q):\n",
    "    \n",
    "    # Insérez votre code ici\n",
    "    \n",
    "    return None\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Lancer la cellule suivante pour tester votre fonction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"K-L Divergence:\", KLDivergence(P, Q))\n",
    "print(\"J-S Divergence:\", JSDivergence(P, Q))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mesure de la dérive de variables quantitatives.\n",
    "\n",
    "Soit $P$ une mesure empirique d'échantillons $X_1, \\ldots, X_n\n",
    "$ et $Q$ une mesure empirique d'échantillons $Y_1, \\ldots, Y_n$, on définit la **Distance de Wasserstein** d'ordre $p$ par la fonction suivante :\n",
    "\n",
    "$$W_p(P, Q) = \\left( \\frac{1}{n}\\sum_{i=1}^n \\|X_{(i)} - Y_{(i)}\\|^p \\right)^{1/p}$$\n",
    "\n",
    "où $X_{(1)}, \\ldots, X_{(n)}$ et $Y_{(1)}, \\ldots, Y_{(n)}$ sont les [**statistiques d'ordre**](https://en.wikipedia.org/wiki/Order_statistic#Notation_and_examples) des échantillons $X$ et $Y$ et $p$ un nombre entier positif.\n",
    "\n",
    "### Exercice\n",
    "\n",
    "* Implémenter une fonction nommée **`WassersteinDistance(X, Y, p)`** permettant de calculer cette métrique à l'ordre **`p`** à partir de **deux échantillons** **`X`** et **`Y`** que l'on supposera de même longueur.\n",
    "\n",
    "**Conseils**:\n",
    "* Vous pouvez trier les échantillons pour obtenir les statistiques d'ordre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def WassersteinDistance(X, Y, p):\n",
    "    \n",
    "    # Insérez votre code ici\n",
    "    \n",
    "    return None\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Lancer la cellule suivante pour tester votre fonction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.random.beta(2, 6, 100)\n",
    "\n",
    "Y = np.random.beta(3, 6, 100)\n",
    "\n",
    "WassersteinDistance(X, Y, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Étude de la dérive du modèle.\n",
    "\n",
    "* En vous appuyant sur les métriques définies précédemment, illustrez et analysez visuellement la **dérive des données** ainsi que **la dérive du modèle** sur les périodes **1 à 3**. \n",
    "\n",
    "\n",
    "* Commenter les visualisations et déterminer si le modèle doit être mis à jour ou si sa performance est toujours acceptable. \n",
    "\n",
    "**Conseils**:\n",
    "* Vous serez évalué sur **la rigueur et le soin** que vous donnerez à votre analyse, et sur **vos capacités à synthéthiser votre étude**. Vous ne serez pas évalué sur vos conclusions.\n",
    "\n",
    "\n",
    "* Vous pouvez normaliser les données par rapport aux **moyennes et variances que vous calculerez sur la période 0** pour que les distances de Wasserstein pour différentes variables soient facilement comparables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insérez votre code ici\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
